{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "245918b3-be3c-4d1f-9a58-7f2a88d01183",
   "metadata": {},
   "source": [
    "# Project 2\n",
    "### CS 5/7394 - Applied Machine Learning\n",
    "\n",
    "- **Due** - March 11 @ 11:59 pm pushed to Github repo\n",
    "- **Teams** - You can do this project solo or in pairs.  Not 3, not 4 not 5... Max of 2. If a 5394 student pairs with a 7394 student, the pair needs to do the 7394 work. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae9b08f-7745-4dfb-8927-258f22423720",
   "metadata": {},
   "source": [
    "Below are 6 Kaggle Datasets.  You will choose 1 to work with for this project. \n",
    "\n",
    "- [Airfare Prediction Dataset](https://www.kaggle.com/zwartfreak/airline-fare-prediction)\n",
    "- [Chinese Rest Holiday Dataset](https://www.kaggle.com/holoong9291/chinese-rest-holiday-dataset-2020-to-2022)\n",
    "- [Jigsaw Toxic Comment Classification Challenge](https://www.kaggle.com/julian3833/jigsaw-toxic-comment-classification-challenge?select=train.csv)\n",
    "- [Latest Covid 19 Dataset Worldwide](https://www.kaggle.com/sandhyakrishnan02/latest-covid-19-dataset-worldwide)\n",
    "- [Trains](https://www.kaggle.com/vahidehdashti/machinelearningdatabase-trains?select=trains-original.data)\n",
    "- [Football Data top 5 Leagues](https://www.kaggle.com/sanjeetsinghnaik/football-data-top-5-leagues)\n",
    "\n",
    "Merging disparate datasets is a staple of the data exploration process.  Therefore, for which ever data set above that you choose, you will need to independently find **an additional** dataset to merge with your selection.  The only requirement is that it add to the richness of the original dataset. Students in the 7000-level version of the class need to find two additional data sets to merge with the original selection. \n",
    "\n",
    "_Note_: If you want to start with a different data set, you need to get Fontenot's OK first.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126330db-b29f-46d9-b16e-7811612a9e73",
   "metadata": {},
   "source": [
    "### Your Tasks\n",
    "\n",
    "Below, there are cells that provide directions on what to do for the project.  \n",
    "\n",
    "You can insert as many cells between the ones below as you'd like, but please **Do NOT** change the cells already provided. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2ca87f-07eb-4792-b76e-15f2f01d1408",
   "metadata": {},
   "source": [
    "### Part 1 - Getting Started\n",
    "\n",
    "- Import libraries\n",
    "- Load original Data (which ever one you chose from the provided list) into a data frame. \n",
    "- Load your additional data set(s) into a data frame. \n",
    "- In a markdown cell, provide a brief description of your the data sets you've chosen to work with.  \n",
    "- Develop a list of 3 - 4 questions that you hope to be able to answer after the exploration of the data and write them in this section. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966ebf41",
   "metadata": {},
   "source": [
    "Our second dataset was collected here and is the 5 year history of Pfizer Inc. stock performance, you can find it here: https://www.nasdaq.com/market-activity/stocks/pfe/historical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ef9b70f5-346e-47af-9d38-043de6663c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "covid = pd.read_csv(\"owid-covid-data.csv\")\n",
    "pfe = pd.read_csv(\"PFE.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420b4751",
   "metadata": {},
   "source": [
    "Our goal is to look at the relationship between worldwide daily new cases and deaths due to COVID-19 and the stock performance of Pfizer Inc. Pfizer Inc. was one of main companies behind the development of a COVID-19 vaccine. First we begin by combining the total new cases and new deaths for all countries by date below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6e82e3d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2021    365\n",
       "2020    345\n",
       "2022      8\n",
       "Name: year, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covid[\"date\"] = pd.to_datetime(covid[\"date\"])\n",
    "covid.drop(covid.index[covid[\"location\"] != \"United States\"], inplace = True)\n",
    "covid['year'] = pd.DatetimeIndex(covid['date']). year\n",
    "covid[\"year\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef673c6f",
   "metadata": {},
   "source": [
    "We remove all rows from the Pfizer stock performance dataset that contain before the beginning of our COVID-19 data set begins, meaning any rows with dates prior to the beginning of 2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bd8644aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pfe[\"Date\"] = pd.to_datetime(pfe[\"Date\"])\n",
    "pfe.drop(pfe.index[pfe[\"Date\"].apply(lambda x: x.year) < 2020], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b04525",
   "metadata": {},
   "source": [
    "The pricing data within the Pfizer dataset is also a string object not a float, we will fix this below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "93cf1102",
   "metadata": {},
   "outputs": [],
   "source": [
    "pfe[pfe.columns[1:]] = pfe[pfe.columns[1:]].replace('[\\$,]', '', regex = True).astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc8b1e5-3e29-4da6-8d36-0e7cf48a3e59",
   "metadata": {},
   "source": [
    "### Part 2 - Data Inspection\n",
    "\n",
    "Write some code to summarize the datasets.  Think about the following questions:\n",
    "- What type of data is each variable? (think like a data scientist here, not a computer scientist)\n",
    "- What is the total size of the data sets?\n",
    "- What time boundaries are there in the dataset?  IOW, what time frame do they span?\n",
    "- Are there any missing values in any of the variables? \n",
    "\n",
    "Do this with Intentionality.  Don't skimp. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "31ea0e37-841e-4be8-95c3-40c54118a52b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 718 entries, 144796 to 145513\n",
      "Data columns (total 68 columns):\n",
      " #   Column                                      Non-Null Count  Dtype         \n",
      "---  ------                                      --------------  -----         \n",
      " 0   iso_code                                    718 non-null    object        \n",
      " 1   continent                                   718 non-null    object        \n",
      " 2   location                                    718 non-null    object        \n",
      " 3   date                                        718 non-null    datetime64[ns]\n",
      " 4   total_cases                                 718 non-null    float64       \n",
      " 5   new_cases                                   717 non-null    float64       \n",
      " 6   new_cases_smoothed                          712 non-null    float64       \n",
      " 7   total_deaths                                680 non-null    float64       \n",
      " 8   new_deaths                                  680 non-null    float64       \n",
      " 9   new_deaths_smoothed                         680 non-null    float64       \n",
      " 10  total_cases_per_million                     718 non-null    float64       \n",
      " 11  new_cases_per_million                       717 non-null    float64       \n",
      " 12  new_cases_smoothed_per_million              712 non-null    float64       \n",
      " 13  total_deaths_per_million                    680 non-null    float64       \n",
      " 14  new_deaths_per_million                      680 non-null    float64       \n",
      " 15  new_deaths_smoothed_per_million             680 non-null    float64       \n",
      " 16  reproduction_rate                           670 non-null    float64       \n",
      " 17  icu_patients                                543 non-null    float64       \n",
      " 18  icu_patients_per_million                    543 non-null    float64       \n",
      " 19  hosp_patients                               543 non-null    float64       \n",
      " 20  hosp_patients_per_million                   543 non-null    float64       \n",
      " 21  weekly_icu_admissions                       0 non-null      float64       \n",
      " 22  weekly_icu_admissions_per_million           0 non-null      float64       \n",
      " 23  weekly_hosp_admissions                      537 non-null    float64       \n",
      " 24  weekly_hosp_admissions_per_million          537 non-null    float64       \n",
      " 25  new_tests                                   673 non-null    float64       \n",
      " 26  total_tests                                 673 non-null    float64       \n",
      " 27  total_tests_per_thousand                    673 non-null    float64       \n",
      " 28  new_tests_per_thousand                      673 non-null    float64       \n",
      " 29  new_tests_smoothed                          666 non-null    float64       \n",
      " 30  new_tests_smoothed_per_thousand             666 non-null    float64       \n",
      " 31  positive_rate                               666 non-null    float64       \n",
      " 32  tests_per_case                              666 non-null    float64       \n",
      " 33  tests_units                                 673 non-null    object        \n",
      " 34  total_vaccinations                          388 non-null    float64       \n",
      " 35  people_vaccinated                           388 non-null    float64       \n",
      " 36  people_fully_vaccinated                     388 non-null    float64       \n",
      " 37  total_boosters                              149 non-null    float64       \n",
      " 38  new_vaccinations                            385 non-null    float64       \n",
      " 39  new_vaccinations_smoothed                   391 non-null    float64       \n",
      " 40  total_vaccinations_per_hundred              388 non-null    float64       \n",
      " 41  people_vaccinated_per_hundred               388 non-null    float64       \n",
      " 42  people_fully_vaccinated_per_hundred         388 non-null    float64       \n",
      " 43  total_boosters_per_hundred                  149 non-null    float64       \n",
      " 44  new_vaccinations_smoothed_per_million       391 non-null    float64       \n",
      " 45  new_people_vaccinated_smoothed              391 non-null    float64       \n",
      " 46  new_people_vaccinated_smoothed_per_hundred  391 non-null    float64       \n",
      " 47  stringency_index                            714 non-null    float64       \n",
      " 48  population                                  718 non-null    float64       \n",
      " 49  population_density                          718 non-null    float64       \n",
      " 50  median_age                                  718 non-null    float64       \n",
      " 51  aged_65_older                               718 non-null    float64       \n",
      " 52  aged_70_older                               718 non-null    float64       \n",
      " 53  gdp_per_capita                              718 non-null    float64       \n",
      " 54  extreme_poverty                             718 non-null    float64       \n",
      " 55  cardiovasc_death_rate                       718 non-null    float64       \n",
      " 56  diabetes_prevalence                         718 non-null    float64       \n",
      " 57  female_smokers                              718 non-null    float64       \n",
      " 58  male_smokers                                718 non-null    float64       \n",
      " 59  handwashing_facilities                      0 non-null      float64       \n",
      " 60  hospital_beds_per_thousand                  718 non-null    float64       \n",
      " 61  life_expectancy                             718 non-null    float64       \n",
      " 62  human_development_index                     718 non-null    float64       \n",
      " 63  excess_mortality_cumulative_absolute        97 non-null     float64       \n",
      " 64  excess_mortality_cumulative                 97 non-null     float64       \n",
      " 65  excess_mortality                            97 non-null     float64       \n",
      " 66  excess_mortality_cumulative_per_million     97 non-null     float64       \n",
      " 67  year                                        718 non-null    int64         \n",
      "dtypes: datetime64[ns](1), float64(62), int64(1), object(4)\n",
      "memory usage: 387.0+ KB\n"
     ]
    }
   ],
   "source": [
    "covid.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "97988a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 544 entries, 0 to 543\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count  Dtype         \n",
      "---  ------      --------------  -----         \n",
      " 0   Date        544 non-null    datetime64[ns]\n",
      " 1   Close/Last  544 non-null    float64       \n",
      " 2   Volume      544 non-null    float64       \n",
      " 3   Open        544 non-null    float64       \n",
      " 4   High        544 non-null    float64       \n",
      " 5   Low         544 non-null    float64       \n",
      "dtypes: datetime64[ns](1), float64(5)\n",
      "memory usage: 29.8 KB\n"
     ]
    }
   ],
   "source": [
    "pfe.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f816006c-868c-4863-b0b8-e56e8a1ec8f3",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Part 3 - Data Description\n",
    "\n",
    "- Create a data description (data dictionary) for your data sets.\n",
    "    - Describe each variable\n",
    "    - If categorical, what levels are present? If the levels are encoded, what do the codes mean?\n",
    "    - If numeric, provide min, max, median and any other univariate stats you'd like to add in. \n",
    "- Where appropriate, provide histograms or other visualizations to characterize each variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e72e20-2c70-4d51-9662-d373f5c2306c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e3afbb04-3bee-4c47-b4ba-d2bfc247492a",
   "metadata": {},
   "source": [
    "### Part 4 - Merge the data\n",
    "\n",
    "Now that you have a better feel for each of your two (or three, for the 7394 students) data sets, it is time to merge them. Describe your strategy for merging the data sets and then actually perform the merge.  \n",
    "\n",
    "Develop a strategy for verifying that the data is properly merged (hoping and finger-crossing are not valid strategies). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccfb384-f695-4a49-a084-d373d45111f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3063ca2e-ec1b-4799-bc76-4a464fc82921",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Part 5 - Explore Bivariate relationships\n",
    "\n",
    "- Choose a reasoned set of variables to explore further.  You don't have to explore all possible pairs of variables, nor do we want to grade that much.  Choose 7 - 9 variables. One should be a variable that you'd like to predict (target variable) using the others (predictor variables). \n",
    "- List your predictor variables\n",
    "- List your target variable\n",
    "- Briefly describe why you have chosen these. \n",
    "\n",
    "Use any of the available visualizations from Seaborn to explore the relationships between the variables. Explore the relationships among the predictor variables as well as the relationship between each predictor variable and the target variable.  Which of the predictor variables are most strongly related?  Are there any interesting relationships between categorical predictors and numeric predictors?  If there are any dichotomous variables, does that influence any of the relationships? Are the relationships positive or negative? \n",
    "\n",
    "Below each plot, you should provide a description and interpretation of the plot.  Make sure to include why the variables in that plot were chosen and what you hope the reader would gain from it as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4058bb4e-b6a0-4d4f-b271-cd0ec29951ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
